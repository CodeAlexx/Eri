"""
Chroma Component for SD Forms
Integrates lodestone's Flow modifications and Chroma model for color-controlled Flux generation
Requires: https://github.com/lodestone-rock/flow
Model: https://huggingface.co/lodestones/Chroma
"""

from typing import List, Optional, Dict, Any, Union, Tuple
from pathlib import Path
import torch
from PIL import Image
import json
import gc
import numpy as np

from .base import VisualComponent
from ..core import (
    Port, 
    PropertyDefinition, 
    PropertyType,
    ComponentStatus,
    PortType,
    PortDirection,
    create_port,
    create_property_definition
)

class ChromaComponent(VisualComponent):
    """Chroma-enhanced Flux Component with color conditioning"""
    
    component_type = "chroma"
    display_name = "Chroma Flux"
    category = "Models"
    icon = "ðŸŽ¨"
    
    # Define input ports
    input_ports = [
        create_port("color_reference", PortType.IMAGE, PortDirection.INPUT, optional=True),
        create_port("color_mask", PortType.IMAGE, PortDirection.INPUT, optional=True),
    ]
    
    # Define output ports
    output_ports = [
        create_port("pipeline", PortType.PIPELINE, PortDirection.OUTPUT),
        create_port("conditioning", PortType.CONDITIONING, PortDirection.OUTPUT),
        create_port("color_conditioning", PortType.CONDITIONING, PortDirection.OUTPUT),
        create_port("model_info", PortType.TEXT, PortDirection.OUTPUT),
    ]
    
    # Define properties
    property_definitions = [
        # Model Selection
        PropertyDefinition(
            key="flux_variant",
            display_name="Base Flux Model", 
            type=PropertyType.ENUM,
            default="flux-dev",
            category="Model",
            metadata={
                "values": ["flux-dev", "flux-schnell", "custom"],
                "description": "Base Flux model to use with Chroma"
            }
        ),
        PropertyDefinition(
            key="flux_model_path",
            display_name="Flux Model Path",
            type=PropertyType.FILE_PICKER,
            default="",
            category="Model",
            metadata={
                "filter": "*.safetensors;*.gguf;*.bin",
                "description": "Path to base Flux model"
            }
        ),
        PropertyDefinition(
            key="chroma_model_path",
            display_name="Chroma Model Path",
            type=PropertyType.FILE_PICKER,
            default="",
            category="Model",
            metadata={
                "filter": "*.safetensors;*.bin",
                "description": "Path to Chroma model (auto-downloads if empty)"
            }
        ),
        
        # Color Control
        PropertyDefinition(
            key="color_mode",
            display_name="Color Mode",
            type=PropertyType.ENUM,
            default="palette",
            category="Color Control",
            metadata={
                "values": ["palette", "reference_image", "color_map", "gradient"],
                "description": "How to specify colors for generation"
            }
        ),
        PropertyDefinition(
            key="color_palette",
            display_name="Color Palette",
            type=PropertyType.COLLECTION,
            default=[],
            category="Color Control",
            metadata={
                "item_schema": {
                    "color": {
                        "type": PropertyType.COLOR,
                        "default": "#FF0000",
                        "display_name": "Color"
                    },
                    "weight": {
                        "type": PropertyType.FLOAT,
                        "default": 1.0,
                        "min": 0.0,
                        "max": 2.0,
                        "step": 0.1,
                        "display_name": "Weight"
                    },
                    "location": {
                        "type": PropertyType.ENUM,
                        "default": "anywhere",
                        "values": ["anywhere", "foreground", "background", "specific_region"],
                        "display_name": "Location"
                    }
                },
                "description": "Define color palette for generation"
            },
            depends_on=["color_mode"]
        ),
        PropertyDefinition(
            key="color_gradient",
            display_name="Color Gradient",
            type=PropertyType.STRING,
            default="",
            category="Color Control",
            metadata={
                "placeholder": "#FF0000,#00FF00,#0000FF",
                "description": "Comma-separated hex colors for gradient"
            },
            depends_on=["color_mode"]
        ),
        PropertyDefinition(
            key="color_preset",
            display_name="Color Preset",
            type=PropertyType.ENUM,
            default="custom",
            category="Color Control",
            metadata={
                "values": [
                    "custom",
                    "vibrant_sunset",
                    "ocean_depths", 
                    "forest_greens",
                    "cyberpunk_neon",
                    "pastel_dreams",
                    "monochrome",
                    "complementary"
                ],
                "description": "Quick color palette presets"
            }
        ),
        
        # Text Prompts
        PropertyDefinition(
            key="prompt",
            display_name="Prompt",
            type=PropertyType.TEXT_MULTILINE,
            default="",
            category="Prompting",
            metadata={
                "placeholder": "Describe your image (colors will be applied via Chroma)...",
                "syntax": "flux-prompt"
            }
        ),
        PropertyDefinition(
            key="negative_prompt",
            display_name="Negative Prompt",
            type=PropertyType.TEXT_MULTILINE,
            default="",
            category="Prompting"
        ),
        PropertyDefinition(
            key="color_prompt",
            display_name="Color Description",
            type=PropertyType.TEXT,
            default="",
            category="Prompting",
            metadata={
                "placeholder": "vibrant sunset colors, warm tones",
                "description": "Natural language color description"
            }
        ),
        
        # Chroma-Specific Settings
        PropertyDefinition(
            key="chroma_strength",
            display_name="Chroma Strength",
            type=PropertyType.FLOAT,
            default=1.0,
            category="Chroma Settings",
            metadata={
                "min": 0.0,
                "max": 2.0,
                "step": 0.1,
                "description": "How strongly to apply color conditioning"
            }
        ),
        PropertyDefinition(
            key="color_guidance_scale",
            display_name="Color Guidance Scale",
            type=PropertyType.FLOAT,
            default=7.5,
            category="Chroma Settings",
            metadata={
                "min": 0.0,
                "max": 20.0,
                "step": 0.5,
                "description": "Separate guidance for color conditioning"
            }
        ),
        PropertyDefinition(
            key="color_steps_ratio",
            display_name="Color Steps Ratio",
            type=PropertyType.FLOAT,
            default=0.5,
            category="Chroma Settings",
            metadata={
                "min": 0.0,
                "max": 1.0,
                "step": 0.05,
                "description": "When to stop color guidance (0.5 = halfway)"
            }
        ),
        
        # Generation Settings
        PropertyDefinition(
            key="guidance_scale",
            display_name="Guidance Scale",
            type=PropertyType.FLOAT,
            default=3.5,
            category="Generation",
            metadata={
                "min": 0.0, 
                "max": 20.0, 
                "step": 0.5,
                "flux_dev_default": 3.5,
                "flux_schnell_default": 0.0
            }
        ),
        PropertyDefinition(
            key="num_inference_steps",
            display_name="Steps",
            type=PropertyType.INTEGER,
            default=20,
            category="Generation",
            metadata={
                "min": 1, 
                "max": 100,
                "flux_dev_default": 50,
                "flux_schnell_default": 4
            }
        ),
        
        # LoRA Settings
        PropertyDefinition(
            key="loras",
            display_name="LoRA Models",
            type=PropertyType.COLLECTION,
            default=[],
            category="LoRA",
            metadata={
                "item_schema": {
                    "path": {
                        "type": PropertyType.FILE_PICKER,
                        "filter": "*.safetensors;*.bin",
                        "display_name": "LoRA Path"
                    },
                    "strength": {
                        "type": PropertyType.FLOAT,
                        "default": 1.0,
                        "min": -2.0,
                        "max": 2.0,
                        "step": 0.1,
                        "display_name": "Strength"
                    },
                    "enabled": {
                        "type": PropertyType.BOOLEAN,
                        "default": True,
                        "display_name": "Enabled"
                    },
                    "targets": {
                        "type": PropertyType.ENUM,
                        "default": "both",
                        "values": ["both", "flux_only", "chroma_only"],
                        "display_name": "Apply To"
                    }
                },
                "description": "Add LoRAs for Flux base model or Chroma adapter. LoRAs with 'chroma' or 'color' in the name are auto-detected."
            }
        ),
        PropertyDefinition(
            key="lora_merge_strategy",
            display_name="LoRA Merge Strategy",
            type=PropertyType.ENUM,
            default="sequential",
            category="LoRA",
            metadata={
                "values": ["sequential", "weighted", "concatenate"],
                "description": "How to apply multiple LoRAs"
            }
        ),
        
        # Advanced
        PropertyDefinition(
            key="enable_flow_matching",
            display_name="Enable Flow Matching",
            type=PropertyType.BOOLEAN,
            default=True,
            category="Advanced",
            metadata={
                "description": "Use lodestone's flow matching modifications"
            }
        ),
        PropertyDefinition(
            key="cache_chroma_model",
            display_name="Cache Chroma Model",
            type=PropertyType.BOOLEAN,
            default=True,
            category="Advanced",
            metadata={
                "description": "Keep Chroma model in memory between generations"
            }
        ),
        
        # Memory Settings
        PropertyDefinition(
            key="enable_cpu_offload",
            display_name="CPU Offload",
            type=PropertyType.BOOLEAN,
            default=False,
            category="Memory"
        ),
        PropertyDefinition(
            key="chroma_on_cpu",
            display_name="Chroma on CPU",
            type=PropertyType.BOOLEAN,
            default=False,
            category="Memory",
            metadata={
                "description": "Keep Chroma model on CPU to save VRAM"
            }
        ),
    ]
    
    def __init__(self, id: str = None):
        super().__init__(id)
        self.pipeline = None
        self.chroma_model = None
        self.flow_pipeline = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self._flow_available = False
        self._user_modified_properties = set()
        self.loaded_loras = []
        self._check_flow_installation()
        
        # Color presets
        self.color_presets = {
            "vibrant_sunset": [
                {"color": "#FF6B6B", "weight": 1.2, "location": "background"},
                {"color": "#FFD93D", "weight": 1.0, "location": "anywhere"},
                {"color": "#FF6BCB", "weight": 0.8, "location": "anywhere"}
            ],
            "ocean_depths": [
                {"color": "#0A2463", "weight": 1.0, "location": "background"},
                {"color": "#3E92CC", "weight": 1.0, "location": "anywhere"},
                {"color": "#2EC4B6", "weight": 0.8, "location": "foreground"}
            ],
            "forest_greens": [
                {"color": "#2D4A23", "weight": 1.0, "location": "background"},
                {"color": "#52B788", "weight": 1.2, "location": "anywhere"},
                {"color": "#95D5B2", "weight": 0.7, "location": "foreground"}
            ],
            "cyberpunk_neon": [
                {"color": "#FF006E", "weight": 1.5, "location": "anywhere"},
                {"color": "#8338EC", "weight": 1.2, "location": "anywhere"},
                {"color": "#06FFB4", "weight": 1.0, "location": "foreground"}
            ],
            "pastel_dreams": [
                {"color": "#FFB5E8", "weight": 1.0, "location": "anywhere"},
                {"color": "#B5DEFF", "weight": 1.0, "location": "anywhere"},
                {"color": "#FFFFD1", "weight": 0.8, "location": "anywhere"}
            ],
            "monochrome": [
                {"color": "#000000", "weight": 1.0, "location": "anywhere"},
                {"color": "#808080", "weight": 0.8, "location": "anywhere"},
                {"color": "#FFFFFF", "weight": 0.6, "location": "anywhere"}
            ],
            "complementary": [
                {"color": "#FF6B6B", "weight": 1.0, "location": "anywhere"},
                {"color": "#6BFFB8", "weight": 1.0, "location": "anywhere"}
            ]
        }
    
    def _check_flow_installation(self):
        """Check if lodestone's flow modifications are available"""
        try:
            # Try to import the flow modifications
            import flow
            from flow import FlowMatchingPipeline
            self._flow_available = True
            print("Flow modifications detected")
        except ImportError:
            print("Flow modifications not found. Installing...")
            self._install_flow()
    
    def _install_flow(self):
        """Attempt to install flow modifications"""
        try:
            import subprocess
            import sys
            
            # Clone and install flow
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", 
                "git+https://github.com/lodestone-rock/flow.git"
            ])
            
            # Try import again
            import flow
            self._flow_available = True
            print("Flow modifications installed successfully")
        except Exception as e:
            print(f"Failed to install flow modifications: {e}")
            print("Please manually install: pip install git+https://github.com/lodestone-rock/flow.git")
            self._flow_available = False
    
    def _download_chroma_model(self):
        """Download Chroma model from HuggingFace if not present"""
        chroma_path = self.properties.get("chroma_model_path", "")
        
        if chroma_path and Path(chroma_path).exists():
            return chroma_path
        
        # Check standard locations
        model_dirs = [
            Path.home() / "models" / "chroma",
            Path("./models/chroma"),
            Path("/home/alex/models/chroma")
        ]
        
        for model_dir in model_dirs:
            chroma_file = model_dir / "chroma_f8_v1.safetensors"
            if chroma_file.exists():
                return str(chroma_file)
        
        # Download from HuggingFace
        try:
            from huggingface_hub import hf_hub_download
            
            print("Downloading Chroma model from HuggingFace...")
            model_dir = model_dirs[0]
            model_dir.mkdir(parents=True, exist_ok=True)
            
            model_file = hf_hub_download(
                repo_id="lodestones/Chroma",
                filename="chroma_f8_v1.safetensors",
                local_dir=str(model_dir)
            )
            
            print(f"Chroma model downloaded to: {model_file}")
            return model_file
            
        except Exception as e:
            print(f"Failed to download Chroma model: {e}")
            return None
    
    def _load_chroma_enhanced_pipeline(self, flux_model_path: str):
        """Load Flux with Chroma enhancements"""
        try:
            if self._flow_available:
                from flow import FlowMatchingPipeline, ChromaAdapter
                
                print("Loading Flux with Flow modifications...")
                
                # Create Flow-enhanced pipeline
                self.flow_pipeline = FlowMatchingPipeline.from_pretrained(
                    flux_model_path,
                    torch_dtype=torch.float16 if self.device.type == "cuda" else torch.float32
                )
                
                # Load Chroma adapter
                chroma_path = self._download_chroma_model()
                if chroma_path:
                    print(f"Loading Chroma adapter from: {chroma_path}")
                    self.chroma_model = ChromaAdapter.from_pretrained(
                        chroma_path,
                        torch_dtype=torch.float16 if self.device.type == "cuda" else torch.float32
                    )
                    
                    # Attach Chroma to pipeline
                    self.flow_pipeline.attach_chroma(self.chroma_model)
                
                self.pipeline = self.flow_pipeline
                
            else:
                # Fallback: Load standard Flux and create mock Chroma
                print("Loading standard Flux (Flow modifications not available)")
                from diffusers import FluxPipeline
                
                self.pipeline = FluxPipeline.from_pretrained(
                    flux_model_path,
                    torch_dtype=torch.float16 if self.device.type == "cuda" else torch.float32
                )
                
                # Create mock Chroma functionality
                self._create_mock_chroma()
            
            # Apply memory settings
            if self.properties.get("enable_cpu_offload", False):
                self.pipeline.enable_model_cpu_offload()
            else:
                self.pipeline = self.pipeline.to(self.device)
            
            if self.chroma_model and self.properties.get("chroma_on_cpu", False):
                self.chroma_model = self.chroma_model.to("cpu")
            
            return True
            
        except Exception as e:
            print(f"Error loading Chroma pipeline: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _load_loras(self):
        """Load and apply LoRA models to Flux and/or Chroma"""
        loras = self.properties.get("loras", [])
        if not loras or not self.pipeline:
            return
        
        try:
            loaded_count = 0
            strategy = self.properties.get("lora_merge_strategy", "sequential")
            self.loaded_loras = []
            
            # Separate LoRAs by target
            flux_loras = []
            chroma_loras = []
            
            for i, lora in enumerate(loras):
                if not lora.get("enabled", True):
                    continue
                    
                lora_path = lora.get("path", "")
                if not lora_path or not Path(lora_path).exists():
                    print(f"LoRA path not found: {lora_path}")
                    continue
                
                targets = lora.get("targets", "both")
                
                # Check if this is a Chroma-specific LoRA by filename
                lora_name = Path(lora_path).name.lower()
                is_chroma_lora = "chroma" in lora_name or "color" in lora_name
                
                if targets == "both":
                    if is_chroma_lora:
                        chroma_loras.append((i, lora))
                    else:
                        flux_loras.append((i, lora))
                elif targets == "flux_only":
                    flux_loras.append((i, lora))
                elif targets == "chroma_only":
                    chroma_loras.append((i, lora))
            
            # Load Flux LoRAs
            if flux_loras and hasattr(self.pipeline, 'load_lora_weights'):
                print(f"Loading {len(flux_loras)} LoRA(s) for Flux")
                flux_adapter_names = []
                flux_adapter_weights = []
                
                for i, lora in flux_loras:
                    lora_path = lora.get("path", "")
                    strength = lora.get("strength", 1.0)
                    adapter_name = f"flux_lora_{i}"
                    
                    try:
                        print(f"Loading Flux LoRA: {Path(lora_path).name} (strength: {strength})")
                        self.pipeline.load_lora_weights(
                            lora_path,
                            adapter_name=adapter_name
                        )
                        
                        flux_adapter_names.append(adapter_name)
                        flux_adapter_weights.append(strength)
                        loaded_count += 1
                        
                        self.loaded_loras.append({
                            "path": lora_path,
                            "name": Path(lora_path).name,
                            "strength": strength,
                            "adapter_name": adapter_name,
                            "target": "flux"
                        })
                        
                    except Exception as e:
                        print(f"Error loading Flux LoRA {lora_path}: {e}")
                
                # Apply Flux LoRAs
                if flux_adapter_names and hasattr(self.pipeline, 'set_adapters'):
                    if strategy == "sequential":
                        for name, weight in zip(flux_adapter_names, flux_adapter_weights):
                            self.pipeline.set_adapters([name], adapter_weights=[weight])
                    elif strategy == "weighted":
                        self.pipeline.set_adapters(flux_adapter_names, adapter_weights=flux_adapter_weights)
                    elif strategy == "concatenate":
                        equal_weights = [1.0 / len(flux_adapter_names)] * len(flux_adapter_names)
                        self.pipeline.set_adapters(flux_adapter_names, adapter_weights=equal_weights)
            
            # Load Chroma LoRAs (if supported by the Chroma adapter)
            if chroma_loras and self.chroma_model and hasattr(self.chroma_model, 'load_lora_weights'):
                print(f"Loading {len(chroma_loras)} LoRA(s) for Chroma")
                
                for i, lora in chroma_loras:
                    lora_path = lora.get("path", "")
                    strength = lora.get("strength", 1.0)
                    
                    try:
                        print(f"Loading Chroma LoRA: {Path(lora_path).name} (strength: {strength})")
                        self.chroma_model.load_lora_weights(
                            lora_path,
                            weight=strength
                        )
                        loaded_count += 1
                        
                        self.loaded_loras.append({
                            "path": lora_path,
                            "name": Path(lora_path).name,
                            "strength": strength,
                            "target": "chroma"
                        })
                        
                    except Exception as e:
                        print(f"Error loading Chroma LoRA {lora_path}: {e}")
            elif chroma_loras:
                print("Chroma adapter doesn't support LoRA loading")
            
            if loaded_count > 0:
                print(f"Loaded {loaded_count} LoRA(s) total")
                
        except Exception as e:
            print(f"Error in LoRA loading: {e}")
            import traceback
            traceback.print_exc()
    
    def _create_mock_chroma(self):
        """Create mock Chroma functionality for testing"""
        print("Creating mock Chroma adapter for testing")
        
        class MockChromaAdapter:
            def __init__(self, device):
                self.device = device
            
            def encode_colors(self, colors, mode="palette"):
                # Simple color encoding mock
                return torch.randn(1, 77, 768).to(self.device)
            
            def apply_color_conditioning(self, latents, color_encoding, strength=1.0):
                # Mock color conditioning
                return latents
        
        self.chroma_model = MockChromaAdapter(self.device)
    
    def _apply_variant_defaults(self):
        """Apply Flux variant specific defaults"""
        flux_variant = self.properties.get("flux_variant", "flux-dev")
        
        # Don't override user-set values
        if not hasattr(self, '_user_modified_properties'):
            self._user_modified_properties = set()
        
        if flux_variant == "flux-schnell":
            if "num_inference_steps" not in self._user_modified_properties:
                self.properties["num_inference_steps"] = 4
            if "guidance_scale" not in self._user_modified_properties:
                self.properties["guidance_scale"] = 0.0
        elif flux_variant == "flux-dev":
            if "num_inference_steps" not in self._user_modified_properties:
                self.properties["num_inference_steps"] = 50
            if "guidance_scale" not in self._user_modified_properties:
                self.properties["guidance_scale"] = 3.5
    
    def _prepare_color_conditioning(self):
        """Prepare color conditioning based on selected mode"""
        color_mode = self.properties.get("color_mode", "palette")
        
        # Apply preset if selected  
        preset = self.properties.get("color_preset", "custom")
        if preset != "custom" and color_mode == "palette":
            preset_colors = self.color_presets.get(preset, [])
            if preset_colors:
                # Only apply preset if user hasn't manually set colors
                current_palette = self.properties.get("color_palette", [])
                if not current_palette or len(current_palette) == 0:
                    self.properties["color_palette"] = preset_colors
        
        if color_mode == "palette":
            colors = self.properties.get("color_palette", [])
            if not colors:
                # Default palette
                colors = [
                    {"color": "#FF6B6B", "weight": 1.0, "location": "anywhere"},
                    {"color": "#4ECDC4", "weight": 0.8, "location": "anywhere"}
                ]
            
            # Convert hex to RGB
            rgb_colors = []
            weights = []
            for color_def in colors:
                hex_color = color_def.get("color", "#000000")
                rgb = tuple(int(hex_color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
                rgb_colors.append(rgb)
                weights.append(color_def.get("weight", 1.0))
            
            return {"colors": rgb_colors, "weights": weights, "mode": "palette"}
            
        elif color_mode == "reference_image":
            ref_image = self.get_input_data("color_reference")
            if ref_image:
                # Extract dominant colors from reference
                return {"image": ref_image, "mode": "reference"}
            
        elif color_mode == "gradient":
            gradient_str = self.properties.get("color_gradient", "")
            if gradient_str:
                colors = []
                for hex_color in gradient_str.split(","):
                    hex_color = hex_color.strip()
                    if hex_color.startswith("#"):
                        rgb = tuple(int(hex_color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
                        colors.append(rgb)
                
                return {"colors": colors, "mode": "gradient"}
        
        # Fallback
        return None
    
    async def process(self, context) -> bool:
        """Process Chroma-enhanced Flux generation"""
        try:
            self.set_status(ComponentStatus.PROCESSING)
            
            # Apply variant-specific defaults
            self._apply_variant_defaults()
            
            # Get Flux model path
            flux_variant = self.properties.get("flux_variant", "flux-dev")
            flux_path = self.properties.get("flux_model_path", "")
            
            if not flux_path:
                # Try to find Flux model
                if flux_variant == "flux-dev":
                    flux_path = "black-forest-labs/FLUX.1-dev"
                elif flux_variant == "flux-schnell":
                    flux_path = "black-forest-labs/FLUX.1-schnell"
                else:
                    raise ValueError("Flux model path not specified")
            
            # Load pipeline if not already loaded
            if self.pipeline is None:
                if not self._load_chroma_enhanced_pipeline(flux_path):
                    raise ValueError("Failed to load Chroma-enhanced pipeline")
            
            # Load LoRAs
            self._load_loras()
            
            # Prepare color conditioning
            color_data = self._prepare_color_conditioning()
            if not color_data:
                print("Warning: No color conditioning specified")
            
            # Prepare text conditioning
            prompt = self.properties.get("prompt", "")
            negative_prompt = self.properties.get("negative_prompt", "")
            color_prompt = self.properties.get("color_prompt", "")
            
            if not prompt:
                prompt = "A high quality image"
            
            # Combine prompts if color prompt specified
            if color_prompt:
                prompt = f"{prompt}, {color_prompt}"
            
            # Create color conditioning
            color_conditioning = None
            if self.chroma_model and color_data:
                if hasattr(self.chroma_model, 'encode_colors'):
                    color_conditioning = self.chroma_model.encode_colors(
                        color_data.get("colors", []),
                        mode=color_data.get("mode", "palette")
                    )
                
            # Set outputs
            self.set_output_data("pipeline", self.pipeline)
            
            conditioning = {
                "prompt": prompt,
                "negative_prompt": negative_prompt,
                "guidance_scale": self.properties.get("guidance_scale", 3.5),
                "num_inference_steps": self.properties.get("num_inference_steps", 20),
                # Chroma-specific
                "color_guidance_scale": self.properties.get("color_guidance_scale", 7.5),
                "chroma_strength": self.properties.get("chroma_strength", 1.0),
                "color_steps_ratio": self.properties.get("color_steps_ratio", 0.5)
            }
            self.set_output_data("conditioning", conditioning)
            
            if color_conditioning is not None:
                self.set_output_data("color_conditioning", color_conditioning)
            
            # Model info
            model_info = {
                "base_model": flux_variant,
                "has_chroma": self.chroma_model is not None,
                "flow_enabled": self._flow_available,
                "color_mode": self.properties.get("color_mode", "palette"),
                "device": str(self.device),
                "chroma_on_cpu": self.properties.get("chroma_on_cpu", False),
                "loras": [
                    {
                        "path": lora.get("path", ""),
                        "name": lora.get("name", "unknown"),
                        "strength": lora.get("strength", 1.0),
                        "target": lora.get("target", "unknown")
                    }
                    for lora in self.loaded_loras
                ]
            }
            
            self.set_output_data("model_info", model_info)
            
            print(f"Chroma-Flux loaded successfully (Flow: {self._flow_available})")
            
            self.set_status(ComponentStatus.COMPLETE)
            return True
            
        except Exception as e:
            self.set_status(ComponentStatus.ERROR)
            print(f"Error in Chroma component: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def hex_to_rgb(self, hex_color: str) -> Tuple[int, int, int]:
        """Convert hex color to RGB tuple"""
        hex_color = hex_color.lstrip('#')
        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
    
    def set_property(self, key: str, value: Any):
        """Override to track user modifications"""
        if hasattr(super(), 'set_property'):
            super().set_property(key, value)
        else:
            self.properties[key] = value
        
        if not hasattr(self, '_user_modified_properties'):
            self._user_modified_properties = set()
        self._user_modified_properties.add(key)
    
    def unload_model(self):
        """Unload models to free memory"""
        # Track LoRA count before clearing
        lora_count = len(self.loaded_loras)
        
        # Unload LoRAs first
        if self.pipeline and hasattr(self.pipeline, 'unload_lora_weights'):
            try:
                self.pipeline.unload_lora_weights()
            except:
                pass
        
        if self.chroma_model and hasattr(self.chroma_model, 'unload_lora_weights'):
            try:
                self.chroma_model.unload_lora_weights()
            except:
                pass
        
        self.loaded_loras = []
        
        if not self.properties.get("cache_chroma_model", True):
            if self.chroma_model:
                del self.chroma_model
                self.chroma_model = None
        
        if self.pipeline:
            del self.pipeline
            self.pipeline = None
            
        if self.flow_pipeline:
            del self.flow_pipeline
            self.flow_pipeline = None
        
        # Clear GPU cache
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("Chroma models unloaded")
        if lora_count > 0:
            print(f"Unloaded {lora_count} LoRA(s)")
